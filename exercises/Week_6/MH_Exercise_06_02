1. Analyze all jobs that failed (state='DONE' and error_result IS NOT NULL) in the last 14 days. Your task is to extract the individual reason string from every reported error and determine the top 5 most frequently occurring error reasons across all failed jobs. (Hint: the error_result field is a STRUCT and the errors sub-field is a repeated array. You'll want to use UNNEST in this query.)
--NOTE: I didn't have to use UNNEST in this one. All of the reasons were "invalidQuery", so I don't know if that had anything to do with it.


SELECT creation_time, error_result.reason
FROM `region-us`.INFORMATION_SCHEMA.JOBS
WHERE state='DONE' 
  AND error_result IS NOT NULL
  AND creation_time >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 14 DAY);


2. For all successful (state='DONE' and error_result IS NULL) query jobs completed in the last 7 days, return the job ID, the total tebibytes billed, and a unique, aggregated list (an array) of all project IDs, dataset IDs, and table IDs referenced in the query. The information is contained in the referenced_tables field. This shows which jobs consumed the most resources and what tables the data is coming from as well as converting the usage unit to the unit used for billing. The INFORMATION_SCHEMA.JOBS view has a total_bytes_billed field, the conversion from bytes to tebibytes is 1024 to the 4th power.
(Hint: Look at array functions, particularly ARRAY_AGG. You'll also need to UNNEST the referenced_tables field.)

--NOTE: I'm not totally sure what I'm supposed to do. Make one array overall, or one array per field (project ID, dataset ID, and table ID).

SELECT 
  job_id, 
  total_bytes_billed / (POW(1024,4)) AS tebibytes_billed,
  ARRAY_AGG(DISTINCT rt.project_id) AS project_ids,
  ARRAY_AGG(DISTINCT rt.dataset_id) AS dataset_ids,
  ARRAY_AGG(DISTINCT rt.table_id) AS table_ids
FROM `region-us`.INFORMATION_SCHEMA.JOBS,
  UNNEST(referenced_tables) rt 
WHERE state='DONE' 
  AND error_result IS NULL
  AND creation_time >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 7 DAY)
GROUP BY job_id, tebibytes_billed;

--3. Identify the single, longest-running QUERY job (based on job duration) created in the last 7 days. Once identified, return its job ID, its total duration in seconds, and the elapsed milliseconds (elapsed_ms) of its first recorded timeline event (index 0) and the elapsed milliseconds of its last recorded timeline event.
--(Hint: the timeline field contains snapshots of the query execution. You'll want to access the first array element and the last but remember that there is not a standard number of elements in the array so getting the last element will need to depend on the array length.)

SELECT 
  job_id,
  TIMESTAMP_DIFF(end_time, start_time, SECOND) AS job_duration_seconds,
  timeline[0].elapsed_ms AS first_seconds,
  timeline[ARRAY_LENGTH(timeline) - 1].elapsed_ms AS last_seconds
FROM `region-us`.INFORMATION_SCHEMA.JOBS
WHERE creation_time >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 7 DAY)

-- 4. Using the created table, calculate the total number of individual drug exposures per person_id and drug_concept_id. Order by largest exposure count.
-- (Hint: use JSON_QUERY_ARRAY to convert the JSON field into a native array, then use ARRAY_LENGTH.)

SELECT
  person_id,
  drug_concept_id,
  ARRAY_LENGTH(JSON_QUERY_ARRAY(drug_exposures_json)) AS num_exposures
FROM `theta-carving-467521-p6.cms_drugs.drug_exposures`
ORDER BY num_exposures DESC;

-- 5. Identify all person_id and drug_concept_id pairs where any of the individual drug exposures (in the native JSON field) had a days_supply greater than 30 (indicating a long-term prescription). For these specific groupings, calculate the average days_supply for only the exposures that meet the greater-than-30-day criterion.
-- (Hint: UNNEST the result of JSON_QUERY_ARRAY to flatten the JSON structure. You'll be able to use JSON_VALUE to extract specific elements by their key name but be aware that the value is always a STRING.)

SELECT
  person_id,
  drug_concept_id,
  AVG(CAST(JSON_VALUE(de.days_supply) AS int64))
FROM `theta-carving-467521-p6.cms_drugs.drug_exposures`,
  UNNEST(JSON_QUERY_ARRAY(drug_exposures_json)) AS de
WHERE CAST(JSON_VALUE(de.days_supply) AS int64) > 30
GROUP BY person_id, drug_concept_id;

-- Going back to the INFORMATION_SCHEMA.JOBS view, identify the top 5 completed QUERY jobs (in the last 7 days) that had the single longest-running execution stage. The job_stages field has details on each execution stage. For each of these 5 jobs, return the job ID, the total job duration, the ID of the single longest stage within that job, and that stage's duration in seconds.
-- (Hint: you can use start_ms and end_ms to calculated the duration of each stage. You'll also need to flatten the job stages array with UNNEST.)

WITH longest_stages AS (
  SELECT 
    job_id,
    MAX(js.end_ms - js.start_ms) AS longest_stage
  FROM `region-us`.INFORMATION_SCHEMA.JOBS,
    UNNEST(job_stages) AS js
  WHERE creation_time >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 7 DAY)
  GROUP BY job_id
  ORDER BY longest_stage DESC
  LIMIT 5
)
SELECT
  ls.job_id,
  TIMESTAMP_DIFF(end_time, start_time, SECOND) AS job_duration_seconds,
  js.id,
  ls.longest_stage
FROM `region-us`.INFORMATION_SCHEMA.JOBS j,
  UNNEST(job_stages) AS js
INNER JOIN longest_stages ls
ON ls.job_id = j.job_id
WHERE js.end_ms - js.start_ms = ls.longest_stage;



